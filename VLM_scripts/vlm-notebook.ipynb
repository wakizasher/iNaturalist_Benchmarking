{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11999423,"sourceType":"datasetVersion","datasetId":7548203}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:23:08.327678Z","iopub.execute_input":"2025-05-30T17:23:08.328244Z","iopub.status.idle":"2025-05-30T17:23:14.732071Z","shell.execute_reply.started":"2025-05-30T17:23:08.328215Z","shell.execute_reply":"2025-05-30T17:23:14.731483Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install required packages\nprint(\"ğŸ“¦ Installing required packages...\")\n!pip install qwen-vl-utils --quiet\nprint(\"âœ… Installation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:23:14.733306Z","iopub.execute_input":"2025-05-30T17:23:14.733640Z","iopub.status.idle":"2025-05-30T17:23:20.160418Z","shell.execute_reply.started":"2025-05-30T17:23:14.733624Z","shell.execute_reply":"2025-05-30T17:23:20.159629Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Installing required packages...\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… Installation complete!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport csv\nimport time\nimport torch\nfrom pathlib import Path\nfrom PIL import Image\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# Check GPU\nif torch.cuda.is_available():\n    gpu_props = torch.cuda.get_device_properties(0)\n    print(f\"ğŸ® GPU Information:\")\n    print(f\"   Name: {gpu_props.name}\")\n    print(f\"   VRAM: {gpu_props.total_memory / 1024**3:.1f} GB\")\n    print(f\"   CUDA Version: {torch.version.cuda}\")\n    print(\"âœ… GPU is available and ready!\")\nelse:\n    print(\"âŒ No GPU available! Check your accelerator settings.\")\n    print(\"   Go to Settings (right panel) â†’ Accelerator â†’ GPU T4 x2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:23:20.161423Z","iopub.execute_input":"2025-05-30T17:23:20.161715Z","iopub.status.idle":"2025-05-30T17:23:45.444200Z","shell.execute_reply.started":"2025-05-30T17:23:20.161678Z","shell.execute_reply":"2025-05-30T17:23:45.443421Z"}},"outputs":[{"name":"stderr","text":"2025-05-30 17:23:34.224173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748625814.430195      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748625814.492342      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ® GPU Information:\n   Name: Tesla T4\n   VRAM: 14.7 GB\n   CUDA Version: 12.4\nâœ… GPU is available and ready!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"âœ… Dataset is already available!\")\n\n# Your data is already extracted at this path:\nbase_folder = \"/kaggle/input/inaturalist-flower-images/test_images_200\"\n\nprint(f\"ğŸ“ Base folder: {base_folder}\")\n\n# Check if the folder exists and show its contents\nif os.path.exists(base_folder):\n    contents = os.listdir(base_folder)\n    print(f\"ğŸ“‚ Contents: {contents}\")\n    \n    # Look for seed folders\n    seed_folders = [item for item in contents if item.startswith('seed_')]\n    print(f\"ğŸŒ± Found seed folders: {seed_folders}\")\n    \n    # Check one seed folder to verify structure\n    if seed_folders:\n        sample_seed = seed_folders[0]\n        seed_path = os.path.join(base_folder, sample_seed)\n        flower_folders = os.listdir(seed_path)\n        print(f\"ğŸŒ¸ Flowers in {sample_seed}: {flower_folders}\")\n        \n        # Count images in first flower folder\n        if flower_folders:\n            sample_flower = flower_folders[0]\n            flower_path = os.path.join(seed_path, sample_flower)\n            if os.path.isdir(flower_path):\n                images = [f for f in os.listdir(flower_path) \n                         if f.endswith(('.jpg', '.jpeg', '.png'))]\n                print(f\"ğŸ“Š Sample: {sample_flower} has {len(images)} images\")\n    \n    print(\"âœ… Data structure looks good!\")\n    \nelse:\n    print(\"âŒ Base folder not found!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:23:45.445968Z","iopub.execute_input":"2025-05-30T17:23:45.446495Z","iopub.status.idle":"2025-05-30T17:23:45.454708Z","shell.execute_reply.started":"2025-05-30T17:23:45.446476Z","shell.execute_reply":"2025-05-30T17:23:45.454065Z"}},"outputs":[{"name":"stdout","text":"âœ… Dataset is already available!\nğŸ“ Base folder: /kaggle/input/inaturalist-flower-images/test_images_200\nğŸ“‚ Contents: ['experiment_summary.json', 'seed_123', 'seed_42', 'seed_456']\nğŸŒ± Found seed folders: ['seed_123', 'seed_42', 'seed_456']\nğŸŒ¸ Flowers in seed_123: ['sampling_metadata.json', 'Bellis_perennis', 'Leucanthemum_vulgare', 'Matricaria_chamomilla']\nâœ… Data structure looks good!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(\"ğŸ¤– Loading Qwen2.5-VL-3B model from Hugging Face...\")\nprint(\"This will take 2-3 minutes on first run...\")\n\nmodel_load_start = time.perf_counter()\nmodel_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n\ntry:\n    print(\"ğŸ“¥ Downloading model from Hugging Face...\")\n    \n    # Load model - this DEFINITELY works on Kaggle\n    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n        model_id,\n        torch_dtype=torch.bfloat16,  # T4 GPU supports this\n        device_map=\"auto\",\n        low_cpu_mem_usage=True,\n        trust_remote_code=True,  # Important for Qwen models\n    )\n    \n    processor = AutoProcessor.from_pretrained(\n        model_id,\n        trust_remote_code=True  # Important for Qwen models\n    )\n    \n    # Optimize for inference\n    model.eval()\n    torch.cuda.empty_cache()\n    \n    load_time = time.perf_counter() - model_load_start\n    print(f\"âœ… Model loaded successfully in {load_time:.1f} seconds!\")\n    print(f\"ğŸ“Š Model device: {next(model.parameters()).device}\")\n    print(f\"ğŸ“Š Model dtype: {next(model.parameters()).dtype}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Failed to load model: {e}\")\n    print(\"\\nğŸ” Troubleshooting:\")\n    print(\"1. Make sure GPU is enabled (Settings â†’ Accelerator â†’ GPU T4)\")\n    print(\"2. Make sure Internet is enabled (Settings â†’ Internet â†’ ON)\")\n    print(\"3. Try restarting the notebook if this persists\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:23:45.455373Z","iopub.execute_input":"2025-05-30T17:23:45.455752Z","iopub.status.idle":"2025-05-30T17:24:46.015739Z","shell.execute_reply.started":"2025-05-30T17:23:45.455735Z","shell.execute_reply":"2025-05-30T17:24:46.015133Z"}},"outputs":[{"name":"stdout","text":"ğŸ¤– Loading Qwen2.5-VL-3B model from Hugging Face...\nThis will take 2-3 minutes on first run...\nğŸ“¥ Downloading model from Hugging Face...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a0d3b10769423696d877d2ca88b5ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81973dffcbbc4fc3a3274e90659bcf05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5eb2f399364f3f859a15d9dfc177f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3946b86086ef4fa5ad8caa6d7a2cd84c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03fd967da53e49e3bd5848510a61f92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a9fa94cb43949708f19b2019a57b73c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f180249d30a34802ac3bab9ddf2f8502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4277194b549f4b489327ad4c31a7ad33"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/5.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff99a3a03f74f4b9f465fcd0dc519a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5374f0dc37704518a2b82ab5ceeacbcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8ae470287d42548ef29a183fb165aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7ffcced1024ecdb73d2fae2841b8c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c68d0d577d42dab2b7609f22f19776"}},"metadata":{}},{"name":"stdout","text":"âœ… Model loaded successfully in 60.5 seconds!\nğŸ“Š Model device: cuda:0\nğŸ“Š Model dtype: torch.bfloat16\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# =============================================================================\n# CONFIGURATION - Change these values as needed\n# =============================================================================\nSEED_TO_PROCESS = int(input(\"Enter seed number (42, 123, 456): \"))  # ğŸŒ± Change to 123 or 456 for other seeds\n\nprint(f\"âš™ï¸ Configuration:\")\nprint(f\"   Processing seed: {SEED_TO_PROCESS}\")\n\n# Use the correct path from your Kaggle dataset\nbase_folder = \"/kaggle/input/inaturalist-flower-images/test_images_200\"\n\n# Define paths\nimage_folder = os.path.join(base_folder, f\"seed_{SEED_TO_PROCESS}\")\noutput_csv = f\"human_taxa_results_seed_{SEED_TO_PROCESS}.csv\"\n\nprint(f\"ğŸ“ Looking for images in: {image_folder}\")\nprint(f\"ğŸ’¾ Results will be saved to: {output_csv}\")\n\n# Verify the seed folder exists\nif os.path.exists(image_folder):\n    print(\"âœ… Seed folder found!\")\n    \n    # Quick preview of what's inside\n    contents = os.listdir(image_folder)\n    print(f\"ğŸ“‚ Contents: {contents}\")\n    \nelse:\n    print(\"âŒ Seed folder not found!\")\n    # Show available seeds\n    if os.path.exists(base_folder):\n        available_items = os.listdir(base_folder)\n        seed_folders = [item for item in available_items if item.startswith('seed_')]\n        if seed_folders:\n            available_seeds = [int(s.split('_')[1]) for s in seed_folders]\n            print(f\"ğŸ’¡ Available seeds: {available_seeds}\")\n            print(f\"ğŸ’¡ Change SEED_TO_PROCESS to one of: {available_seeds}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:18:05.234685Z","iopub.execute_input":"2025-05-30T18:18:05.235389Z","iopub.status.idle":"2025-05-30T18:18:09.837693Z","shell.execute_reply.started":"2025-05-30T18:18:05.235367Z","shell.execute_reply":"2025-05-30T18:18:09.836920Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter seed number (42, 123, 456):  456\n"},{"name":"stdout","text":"âš™ï¸ Configuration:\n   Processing seed: 456\nğŸ“ Looking for images in: /kaggle/input/inaturalist-flower-images/test_images_200/seed_456\nğŸ’¾ Results will be saved to: human_taxa_results_seed_456.csv\nâœ… Seed folder found!\nğŸ“‚ Contents: ['sampling_metadata.json', 'Bellis_perennis', 'Leucanthemum_vulgare', 'Matricaria_chamomilla']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(\"ğŸ” Scanning for images...\")\n\nflowers = [\"Bellis_perennis\", \"Leucanthemum_vulgare\", \"Matricaria_chamomilla\"]\nimage_paths = []\n\n# Check if seed folder exists\nif not os.path.exists(image_folder):\n    print(f\"âŒ Seed folder not found: {image_folder}\")\n    \nelse:\n    # Collect images from each flower folder\n    total_images = 0\n    \n    for flower in flowers:\n        flower_folder = os.path.join(image_folder, flower)\n        \n        if os.path.exists(flower_folder):\n            # Find all image files\n            flower_images = []\n            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n                flower_images.extend([\n                    os.path.join(flower_folder, f) \n                    for f in os.listdir(flower_folder) \n                    if f.endswith(ext)\n                ])\n            \n            image_paths.extend(flower_images)\n            total_images += len(flower_images)\n            print(f\"ğŸŒ¸ {flower}: {len(flower_images)} images\")\n            \n        else:\n            print(f\"âŒ Flower folder not found: {flower_folder}\")\n\nprint(f\"\\nğŸ“Š Total images found: {len(image_paths)}\")\n\nif len(image_paths) == 0:\n    print(\"âŒ No images found! Please check your folder structure and seed number.\")\nelse:\n    print(\"âœ… Ready to process images!\")\n    \n    # Show expected processing time\n    estimated_time = len(image_paths) * 1.5 / 60  # 1.5 seconds per image\n    print(f\"â±ï¸  Estimated processing time: {estimated_time:.1f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:18:13.218328Z","iopub.execute_input":"2025-05-30T18:18:13.218603Z","iopub.status.idle":"2025-05-30T18:18:13.238551Z","shell.execute_reply.started":"2025-05-30T18:18:13.218583Z","shell.execute_reply":"2025-05-30T18:18:13.237836Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Scanning for images...\nğŸŒ¸ Bellis_perennis: 200 images\nğŸŒ¸ Leucanthemum_vulgare: 200 images\nğŸŒ¸ Matricaria_chamomilla: 200 images\n\nğŸ“Š Total images found: 600\nâœ… Ready to process images!\nâ±ï¸  Estimated processing time: 15.0 minutes\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"if len(image_paths) > 0:\n    print(f\"ğŸš€ Starting VML processing of {len(image_paths)} images...\")\n    print(\"=\" * 60)\n    \n    processing_start = time.perf_counter()\n    processed_count = 0\n    error_count = 0\n    results = []\n    \n    for i, image_path in enumerate(image_paths):\n        image_file = os.path.basename(image_path)\n        \n        # Extract flower name from filename\n        base_name = os.path.splitext(image_file)[0]\n        name_parts = base_name.split('_')\n        flower_name = \"_\".join(name_parts[:-1]) if len(name_parts) > 1 else base_name\n        \n        # Create prompt\n        prompt = f\"Does this image show any humans or identifiable human body parts (including, but not limited to, faces, hands, fingers, arms, legs, torsos, or silhouettes)? Answer with 'Yes' or 'No' only.\"\n        \n        # Progress updates every 25 images\n        if i % 25 == 0 or i == len(image_paths) - 1:\n            elapsed = time.perf_counter() - processing_start\n            if i > 0:\n                avg_time = elapsed / (i + 1)\n                eta_seconds = (len(image_paths) - i - 1) * avg_time\n                eta_minutes = eta_seconds / 60\n                \n                print(f\"ğŸ“Š Progress: {i+1:3d}/{len(image_paths)} ({(i+1)/len(image_paths)*100:5.1f}%) | \"\n                      f\"Avg: {avg_time:.2f}s/img | ETA: {eta_minutes:.1f}min\")\n        \n        try:\n            # Prepare messages for the model\n            messages = [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n                        {\"type\": \"text\", \"text\": prompt}\n                    ]\n                }\n            ]\n            \n            # Process with model\n            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            image_inputs, video_inputs = process_vision_info(messages)\n            \n            inputs = processor(\n                text=[text],\n                images=image_inputs,\n                videos=video_inputs,\n                padding=True,\n                return_tensors=\"pt\",\n            ).to(model.device)\n\n            # Generate response\n            with torch.no_grad():\n                generated_ids = model.generate(\n                    **inputs, \n                    max_new_tokens=10,\n                    do_sample=False,\n                    pad_token_id=processor.tokenizer.eos_token_id\n                )\n            \n            # Decode response\n            generated_ids_trimmed = [\n                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n            ]\n            response = processor.batch_decode(\n                generated_ids_trimmed, \n                skip_special_tokens=True,\n                clean_up_tokenization_spaces=False\n            )[0].strip()\n\n            # Extract Yes/No result\n            result = \"Yes\" if \"Yes\" in response else \"No\"\n            results.append([image_file, result])\n            processed_count += 1\n            \n            # Show sample results for first few images\n            if i < 3:\n                print(f\"   ğŸ“ Sample {i+1}: {image_file} â†’ {result}\")\n                \n        except Exception as e:\n            print(f\"âŒ Error processing {image_file}: {str(e)}\")\n            results.append([image_file, \"Error\"])\n            error_count += 1\n            \n            # Clear GPU memory after error\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n    # Processing complete\n    total_time = time.perf_counter() - processing_start\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"ğŸ‰ PROCESSING COMPLETE!\")\n    print(\"=\" * 60)\n    print(f\"ğŸ“Š Final Statistics:\")\n    print(f\"   Total images: {len(image_paths)}\")\n    print(f\"   Successfully processed: {processed_count}\")\n    print(f\"   Errors: {error_count}\")\n    print(f\"   Success rate: {(processed_count/len(image_paths))*100:.1f}%\")\n    print(f\"â±ï¸  Performance:\")\n    print(f\"   Total time: {total_time/60:.1f} minutes\")\n    print(f\"   Average per image: {total_time/len(image_paths):.2f} seconds\")\n\nelse:\n    print(\"âŒ No images to process!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:18:16.711888Z","iopub.execute_input":"2025-05-30T18:18:16.712619Z","iopub.status.idle":"2025-05-30T18:34:30.471265Z","shell.execute_reply.started":"2025-05-30T18:18:16.712595Z","shell.execute_reply":"2025-05-30T18:34:30.470505Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Starting VML processing of 600 images...\n============================================================\n   ğŸ“ Sample 1: Bellis_perennis_45972.jpg â†’ No\n   ğŸ“ Sample 2: Bellis_perennis_79728.jpg â†’ No\n   ğŸ“ Sample 3: Bellis_perennis_66939.jpg â†’ No\nğŸ“Š Progress:  26/600 (  4.3%) | Avg: 1.62s/img | ETA: 15.5min\nğŸ“Š Progress:  51/600 (  8.5%) | Avg: 1.65s/img | ETA: 15.1min\nğŸ“Š Progress:  76/600 ( 12.7%) | Avg: 1.67s/img | ETA: 14.6min\nğŸ“Š Progress: 101/600 ( 16.8%) | Avg: 1.65s/img | ETA: 13.7min\nğŸ“Š Progress: 126/600 ( 21.0%) | Avg: 1.63s/img | ETA: 12.9min\nğŸ“Š Progress: 151/600 ( 25.2%) | Avg: 1.63s/img | ETA: 12.2min\nğŸ“Š Progress: 176/600 ( 29.3%) | Avg: 1.63s/img | ETA: 11.5min\nğŸ“Š Progress: 201/600 ( 33.5%) | Avg: 1.63s/img | ETA: 10.8min\nğŸ“Š Progress: 226/600 ( 37.7%) | Avg: 1.63s/img | ETA: 10.2min\nğŸ“Š Progress: 251/600 ( 41.8%) | Avg: 1.63s/img | ETA: 9.5min\nğŸ“Š Progress: 276/600 ( 46.0%) | Avg: 1.63s/img | ETA: 8.8min\nğŸ“Š Progress: 301/600 ( 50.2%) | Avg: 1.63s/img | ETA: 8.1min\nğŸ“Š Progress: 326/600 ( 54.3%) | Avg: 1.63s/img | ETA: 7.4min\nğŸ“Š Progress: 351/600 ( 58.5%) | Avg: 1.63s/img | ETA: 6.8min\nğŸ“Š Progress: 376/600 ( 62.7%) | Avg: 1.63s/img | ETA: 6.1min\nğŸ“Š Progress: 401/600 ( 66.8%) | Avg: 1.62s/img | ETA: 5.4min\nğŸ“Š Progress: 426/600 ( 71.0%) | Avg: 1.63s/img | ETA: 4.7min\nğŸ“Š Progress: 451/600 ( 75.2%) | Avg: 1.63s/img | ETA: 4.1min\nğŸ“Š Progress: 476/600 ( 79.3%) | Avg: 1.63s/img | ETA: 3.4min\nğŸ“Š Progress: 501/600 ( 83.5%) | Avg: 1.63s/img | ETA: 2.7min\nğŸ“Š Progress: 526/600 ( 87.7%) | Avg: 1.62s/img | ETA: 2.0min\nğŸ“Š Progress: 551/600 ( 91.8%) | Avg: 1.62s/img | ETA: 1.3min\nğŸ“Š Progress: 576/600 ( 96.0%) | Avg: 1.62s/img | ETA: 0.6min\nğŸ“Š Progress: 600/600 (100.0%) | Avg: 1.62s/img | ETA: 0.0min\n\n============================================================\nğŸ‰ PROCESSING COMPLETE!\n============================================================\nğŸ“Š Final Statistics:\n   Total images: 600\n   Successfully processed: 600\n   Errors: 0\n   Success rate: 100.0%\nâ±ï¸  Performance:\n   Total time: 16.2 minutes\n   Average per image: 1.62 seconds\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"if 'results' in locals() and results:\n    print(f\"\\nğŸ’¾ Saving results to {output_csv}...\")\n    \n    # Save to CSV\n    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Image_Name\", \"Humans_Present\"])\n        writer.writerows(results)\n    \n    print(f\"âœ… Results saved successfully!\")\n    \n    # Calculate statistics\n    yes_count = sum(1 for result in results if result[1] == \"Yes\")\n    no_count = sum(1 for result in results if result[1] == \"No\")\n    error_count = sum(1 for result in results if result[1] == \"Error\")\n    \n    print(f\"\\nğŸ“ˆ Result Summary:\")\n    print(f\"   ğŸ”´ yes: {yes_count:3d} ({yes_count/len(results)*100:5.1f}%)\")\n    print(f\"   ğŸŸ¢ no:  {no_count:3d} ({no_count/len(results)*100:5.1f}%)\")\n    print(f\"   âš ï¸  Processing errors: {error_count:3d} ({error_count/len(results)*100:5.1f}%)\")\n    \n    # Create download link\n    from IPython.display import FileLink, display\n    print(f\"\\nâ¬‡ï¸  DOWNLOAD YOUR RESULTS:\")\n    display(FileLink(output_csv))\n    \n    # Show sample results\n    print(f\"\\nğŸ” Sample Results (first 10):\")\n    for i, (filename, result) in enumerate(results[:10], 1):\n        status_emoji = \"ğŸ”´\" if result == \"Yes\" else \"ğŸŸ¢\" if result == \"No\" else \"âš ï¸\"\n        print(f\"   {i:2d}. {status_emoji} {filename}: {result}\")\n    \n    if len(results) > 10:\n        print(f\"   ... and {len(results) - 10} more results\")\n\nelse:\n    print(\"âŒ No results to save!\")\n\nprint(f\"\\nâœ… SEED {SEED_TO_PROCESS} PROCESSING COMPLETE!\")\nprint(f\"ğŸ“ Remember to download your CSV file!\")\nprint(f\"ğŸ”„ To process other seeds (123, 456), change SEED_TO_PROCESS in Cell 5 and re-run cells 5-8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:34:30.472637Z","iopub.execute_input":"2025-05-30T18:34:30.472872Z","iopub.status.idle":"2025-05-30T18:34:30.485237Z","shell.execute_reply.started":"2025-05-30T18:34:30.472855Z","shell.execute_reply":"2025-05-30T18:34:30.484364Z"}},"outputs":[{"name":"stdout","text":"\nğŸ’¾ Saving results to human_taxa_results_seed_456.csv...\nâœ… Results saved successfully!\n\nğŸ“ˆ Result Summary:\n   ğŸ”´ yes:  27 (  4.5%)\n   ğŸŸ¢ no:  573 ( 95.5%)\n   âš ï¸  Processing errors:   0 (  0.0%)\n\nâ¬‡ï¸  DOWNLOAD YOUR RESULTS:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/human_taxa_results_seed_456.csv","text/html":"<a href='human_taxa_results_seed_456.csv' target='_blank'>human_taxa_results_seed_456.csv</a><br>"},"metadata":{}},{"name":"stdout","text":"\nğŸ” Sample Results (first 10):\n    1. ğŸŸ¢ Bellis_perennis_45972.jpg: No\n    2. ğŸŸ¢ Bellis_perennis_79728.jpg: No\n    3. ğŸŸ¢ Bellis_perennis_66939.jpg: No\n    4. ğŸŸ¢ Bellis_perennis_29107.jpg: No\n    5. ğŸŸ¢ Bellis_perennis_43031.jpg: No\n    6. ğŸŸ¢ Bellis_perennis_9505.jpg: No\n    7. ğŸ”´ Bellis_perennis_1642.jpg: Yes\n    8. ğŸŸ¢ Bellis_perennis_28510.jpg: No\n    9. ğŸŸ¢ Bellis_perennis_74387.jpg: No\n   10. ğŸŸ¢ Bellis_perennis_42750.jpg: No\n   ... and 590 more results\n\nâœ… SEED 456 PROCESSING COMPLETE!\nğŸ“ Remember to download your CSV file!\nğŸ”„ To process other seeds (123, 456), change SEED_TO_PROCESS in Cell 5 and re-run cells 5-8\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}